{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4534773",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "\n",
    "This notebook loads Amazon product reviews data (2014 dataset) from [Google Drive](\"https://drive.google.com/file/d/11fsXDGy_NpQMIHLowKNcTQoXUkX43x2f/view\") and uses PySpark to transform it into 3 parquet tables:\n",
    "\n",
    "- **User Table**: Contains `userID`, `userName`, and `gender` (gender is inferred from the `userName` field using the gender_guesser library)\n",
    "- **Training Data Table** (70% of reviews): Contains `reviewText` and `semanticDetect` (derived from the `overall` rating field)\n",
    "- **User Comments Table** (30% of reviews): Contains `reviewerID`, `reviewText`, and `overall` rating\n",
    "\n",
    "## Data Transformation Rules\n",
    "\n",
    "### Sentiment Classification (semanticDetect)\n",
    "The `semanticDetect` field is generated from the `overall` rating using the following rules:\n",
    "- If `overall` > 3 → `\"positive\"`\n",
    "- If `overall` < 3 → `\"negative\"`\n",
    "- If `overall` = 3 → `\"neutral\"`\n",
    "\n",
    "## Sample Review Structure\n",
    "```\n",
    "{\n",
    "  \"reviewerID\": \"A2SUAM1J3GNN3B\",\n",
    "  \"asin\": \"0000013714\",\n",
    "  \"reviewerName\": \"J. McDonald\",\n",
    "  \"helpful\": [2, 3],\n",
    "  \"reviewText\": \"I bought this for my husband who plays the piano. He is having a wonderful time playing these old hymns. The music is at times hard to read because we think the book was published for singing from more than playing from. Great purchase though!\",\n",
    "  \"overall\": 5.0,\n",
    "  \"summary\": \"Heavenly Highway Hymns\",\n",
    "  \"unixReviewTime\": 1252800000,\n",
    "  \"reviewTime\": \"09 13, 2009\"\n",
    "}\n",
    "```\n",
    "\n",
    "**Field Descriptions:**\n",
    "- `reviewerID`: Unique identifier for the reviewer (e.g., A2SUAM1J3GNN3B)\n",
    "- `asin`: Amazon Standard Identification Number for the product (e.g., 0000013714)\n",
    "- `reviewerName`: Name of the reviewer\n",
    "- `helpful`: Helpfulness rating as [helpful_votes, total_votes] (e.g., [2, 3] means 2 out of 3 people found it helpful)\n",
    "- `reviewText`: Full text content of the review\n",
    "- `overall`: Product rating on a 1-5 scale\n",
    "- `summary`: Brief summary/title of the review\n",
    "- `unixReviewTime`: Review timestamp in Unix format\n",
    "- `reviewTime`: Human-readable review date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81999c7",
   "metadata": {},
   "source": [
    "# Load data from Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936cd845",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdown\n",
    "import os\n",
    "\n",
    "os.makedirs(\"data/bronze\", exist_ok=True)\n",
    "\n",
    "# Load data from Google Drive\n",
    "file_url = \"https://drive.google.com/file/d/11fsXDGy_NpQMIHLowKNcTQoXUkX43x2f/view\"\n",
    "output_path = \"data/bronze/reviews_Cell_Phones_and_Accessories.jsonl\"\n",
    "gdown.download(file_url, output_path, fuzzy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec8eeeb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"data/bronze/reviews_Cell_Phones_and_Accessories.jsonl\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00813f3f",
   "metadata": {},
   "source": [
    "# Remove rows with null values in reviewText and convert to parquet format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc250111",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(reviewerID='A1GG51FWU0XQYH', asin='098949232X', reviewerName='Paul Williams', helpful=None, reviewText='If your into space this is the Calendar for you.', overall=5.0, summary='Five Stars', unixReviewTime=1416355200, reviewTime='11 19, 2014'), Row(reviewerID='AVFIDS9RK38E0', asin='098949232X', reviewerName='Sean Powell', helpful=None, reviewText='Awesome pictures!', overall=5.0, summary='Five Stars', unixReviewTime=1416355200, reviewTime='11 19, 2014'), Row(reviewerID='A2S4AVR5SJ7KMI', asin='098949232X', reviewerName='Tom Davis', helpful=None, reviewText='Great wall art and information for space exploration minded people.', overall=5.0, summary='Five Stars', unixReviewTime=1416355200, reviewTime='11 19, 2014'), Row(reviewerID='AEMMMVOR9BFLI', asin='098949232X', reviewerName='Kwajmeck', helpful=None, reviewText='As always, it is a quality calendar full of very interesting space-related photos and information.  I love it.  I buy a new one every year.', overall=5.0, summary='I love it. I buy a new one every year', unixReviewTime=1416355200, reviewTime='11 19, 2014'), Row(reviewerID='A2DZXMBTY7KLYP', asin='098949232X', reviewerName='ScottG43', helpful=None, reviewText='This is a fantastic calendar. This is my third year purchasing it. It is sturdy and well put together and has a bunch of awesome information in it.', overall=5.0, summary='Great Calendar.', unixReviewTime=1416355200, reviewTime='11 19, 2014')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records: 10063255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records after dropping columns: 10053033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 10053033 records to data/bronze/reviews_Cell_Phones_and_Accessories\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, when, lit, udf\n",
    "from pyspark.sql.types import (\n",
    "    StructType,\n",
    "    StructField,\n",
    "    StringType,\n",
    "    IntegerType,\n",
    "    DoubleType,\n",
    "    ArrayType,\n",
    "    LongType,\n",
    "    BooleanType\n",
    ")\n",
    "\n",
    "# Count null values\n",
    "def is_empty_or_whitespace(s):\n",
    "    return not s or s.strip() == \"\"\n",
    "\n",
    "# Initialize Schema for the data\n",
    "review_schema = StructType([\n",
    "    StructField(\"reviewerID\", StringType(), True),\n",
    "    StructField(\"asin\", StringType(), True),\n",
    "    StructField(\"reviewerName\", StringType(), True),\n",
    "    StructField(\"helpful\", ArrayType(IntegerType()), True),\n",
    "    StructField(\"reviewText\", StringType(), True),\n",
    "    StructField(\"overall\", DoubleType(), True),\n",
    "    StructField(\"summary\", StringType(), True),\n",
    "    StructField(\"unixReviewTime\", LongType(), True),\n",
    "    StructField(\"reviewTime\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Amazon Product Reviews Transformation\") \\\n",
    "    .config(\"spark.driver.memory\", \"8g\") \\\n",
    "    .config(\"spark.executor.memory\", \"8g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "df = spark.read.schema(review_schema).json(output_path, multiLine=False)\n",
    "\n",
    "# Cache the dataframe\n",
    "print(df.head(5))\n",
    "\n",
    "# Count the number of records\n",
    "records = df.count()\n",
    "print(f\"Total records: {records}\")\n",
    "\n",
    "# Drop unused columns\n",
    "df = df.drop(\"helpful\", \"summary\", \"reviewTime\", \"unixReviewTime\")\n",
    "\n",
    "# Remove rows with null values in reviewText\n",
    "is_empty_udf = udf(is_empty_or_whitespace, BooleanType())\n",
    "\n",
    "# df = df.filter(col(\"reviewText\").isNotNull())\n",
    "# df = df.filter(col(\"reviewerName\").isNotNull())\n",
    "df = df.filter(~is_empty_udf(col(\"reviewText\")))\n",
    "df = df.filter(~is_empty_udf(col(\"reviewerName\")))\n",
    "\n",
    "records2 = df.count()\n",
    "print(f\"Total records after dropping columns: {records2}\")\n",
    "\n",
    "# Write Parquet\n",
    "parquet_path = \"data/bronze/reviews_Cell_Phones_and_Accessories\"\n",
    "df.write.mode(\"overwrite\").parquet(parquet_path)\n",
    "print(f\"Wrote {records2} records to {parquet_path}\")\n",
    "\n",
    "# Clear everything before stopping\n",
    "spark.catalog.clearCache()\n",
    "\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76068a0",
   "metadata": {},
   "source": [
    "## Merge parquet files into 3 files using duckdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f193a07b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Wrote 7037123 records to data/silver/reviews_Cell_Phones_and_Accessories_70.parquet\n",
      "✅ Wrote 3015910 records to data/silver/reviews_Cell_Phones_and_Accessories_30.parquet\n",
      "✅ Wrote all records to data/silver/reviews_Cell_Phones_and_Accessories.parquet\n"
     ]
    }
   ],
   "source": [
    "from duckdb import connect\n",
    "\n",
    "TOTAL_ROWS = 10_053_033\n",
    "SPLIT_70 = 7_037_123 # 70%\n",
    "SPLIT_30 = 3_015_910 # 30%\n",
    "\n",
    "con = connect()\n",
    "\n",
    "# File 1: 70% of the data\n",
    "file1 = \"data/silver/reviews_Cell_Phones_and_Accessories_70.parquet\"\n",
    "con.execute(f\"\"\"\n",
    "    COPY (\n",
    "        SELECT *\n",
    "        FROM (\n",
    "            SELECT *,\n",
    "                ROW_NUMBER() OVER (ORDER BY random()) AS rn\n",
    "            FROM read_parquet('data/bronze/reviews_Cell_Phones_and_Accessories/*.parquet')\n",
    "        )\n",
    "        WHERE rn <= {SPLIT_70}\n",
    "    )\n",
    "    TO '{file1}'\n",
    "    (FORMAT PARQUET, COMPRESSION SNAPPY);\n",
    "\"\"\")\n",
    "\n",
    "print(f\"✅ Wrote {SPLIT_70} records to {file1}\")\n",
    "\n",
    "# File 2: 30% of the data\n",
    "file2 = \"data/silver/reviews_Cell_Phones_and_Accessories_30.parquet\"\n",
    "con.execute(f\"\"\"\n",
    "    COPY (\n",
    "        SELECT *\n",
    "        FROM (\n",
    "            SELECT *,\n",
    "                ROW_NUMBER() OVER (ORDER BY random()) AS rn\n",
    "            FROM read_parquet('data/bronze/reviews_Cell_Phones_and_Accessories/*.parquet')\n",
    "        )\n",
    "        WHERE rn > {SPLIT_70}\n",
    "    )\n",
    "    TO '{file2}'\n",
    "    (FORMAT PARQUET, COMPRESSION SNAPPY);\n",
    "\"\"\")\n",
    "\n",
    "print(f\"✅ Wrote {SPLIT_30} records to {file2}\")\n",
    "\n",
    "# File 3: 100% of the data\n",
    "file3 = \"data/silver/reviews_Cell_Phones_and_Accessories.parquet\"\n",
    "con.execute(f\"\"\"\n",
    "    COPY (\n",
    "        SELECT *\n",
    "        FROM read_parquet('data/bronze/reviews_Cell_Phones_and_Accessories/*.parquet')\n",
    "    )\n",
    "    TO '{file3}'\n",
    "    (FORMAT PARQUET, COMPRESSION SNAPPY);\n",
    "\"\"\")\n",
    "print(f\"✅ Wrote all records to {file3}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7dd6a71",
   "metadata": {},
   "source": [
    "# Check null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f4b58bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records: 10053033\n",
      "[Row(reviewerID='A1GG51FWU0XQYH', asin='098949232X', reviewerName='Paul Williams', reviewText='If your into space this is the Calendar for you.', overall=5.0), Row(reviewerID='AVFIDS9RK38E0', asin='098949232X', reviewerName='Sean Powell', reviewText='Awesome pictures!', overall=5.0), Row(reviewerID='A2S4AVR5SJ7KMI', asin='098949232X', reviewerName='Tom Davis', reviewText='Great wall art and information for space exploration minded people.', overall=5.0), Row(reviewerID='AEMMMVOR9BFLI', asin='098949232X', reviewerName='Kwajmeck', reviewText='As always, it is a quality calendar full of very interesting space-related photos and information.  I love it.  I buy a new one every year.', overall=5.0), Row(reviewerID='A2DZXMBTY7KLYP', asin='098949232X', reviewerName='ScottG43', reviewText='This is a fantastic calendar. This is my third year purchasing it. It is sturdy and well put together and has a bunch of awesome information in it.', overall=5.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null review Text values: 0\n",
      "Null review Overall values: 0\n",
      "Null asin values: 0\n",
      "Null reviewer ID values: 0\n",
      "Null reviewer Name values: 0\n",
      "Empty review Text values: 0\n",
      "Empty reviewer Name values: 0\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import BooleanType\n",
    "\n",
    "FILE = \"data/silver/reviews_Cell_Phones_and_Accessories.parquet\"\n",
    "\n",
    "# Initialize Schema for the data\n",
    "review_schema = StructType([\n",
    "    StructField(\"reviewerID\", StringType(), True),\n",
    "    StructField(\"asin\", StringType(), True),\n",
    "    StructField(\"reviewerName\", StringType(), True),\n",
    "    StructField(\"reviewText\", StringType(), True),\n",
    "    StructField(\"overall\", DoubleType(), True),\n",
    "])\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Amazon Product Reviews Transformation\") \\\n",
    "    .config(\"spark.driver.memory\", \"8g\") \\\n",
    "    .config(\"spark.executor.memory\", \"8g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "df = spark.read.schema(review_schema).parquet(FILE)\n",
    "\n",
    "# Cache the dataframe\n",
    "df.cache()\n",
    "\n",
    "# Count the number of records\n",
    "records = df.count()\n",
    "print(f\"Total records: {records}\")\n",
    "\n",
    "print(df.head(5))\n",
    "\n",
    "# Count null values\n",
    "def is_empty_or_whitespace(s):\n",
    "    return not s or s.strip() == \"\"\n",
    "\n",
    "# Create UDF\n",
    "is_empty_udf = udf(is_empty_or_whitespace, BooleanType())\n",
    "\n",
    "review_text_values_null = df.filter(col(\"reviewText\").isNull()).count()\n",
    "review_overall_values_null = df.filter(col(\"overall\").isNull()).count()\n",
    "asin_values_null = df.filter(col(\"asin\").isNull()).count()\n",
    "reviewer_id_values_null = df.filter(col(\"reviewerID\").isNull()).count()\n",
    "reviewer_name_values_null = df.filter(col(\"reviewerName\").isNull()).count()\n",
    "empty_text_count = df.filter(is_empty_udf(col(\"reviewText\"))).count()\n",
    "empty_name_count = df.filter(is_empty_udf(col(\"reviewerName\"))).count()\n",
    "\n",
    "print(f\"Null review Text values: {review_text_values_null}\")\n",
    "print(f\"Null review Overall values: {review_overall_values_null}\")\n",
    "print(f\"Null asin values: {asin_values_null}\")\n",
    "print(f\"Null reviewer ID values: {reviewer_id_values_null}\")\n",
    "print(f\"Null reviewer Name values: {reviewer_name_values_null}\")\n",
    "print(f\"Empty review Text values: {empty_text_count}\")\n",
    "print(f\"Empty reviewer Name values: {empty_name_count}\")\n",
    "# Clear everything before stopping\n",
    "spark.catalog.clearCache()\n",
    "\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294d62fe",
   "metadata": {},
   "source": [
    "# Create User Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6174f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique users: 6205624\n",
      "Null reviewer ID values: 0\n",
      "Null gender values: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User table written to: data/gold/user_table\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, rand\n",
    "from pyspark.sql.types import (\n",
    "    StructType,\n",
    "    StructField,\n",
    "    StringType,\n",
    "    DoubleType\n",
    ")\n",
    "\n",
    "BASE_FILE = \"data/silver/reviews_Cell_Phones_and_Accessories.parquet\"\n",
    "DEST_FILE = \"data/gold/user_table\"\n",
    "\n",
    "# Initialize Schema for the data\n",
    "review_schema = StructType([\n",
    "    StructField(\"reviewerID\", StringType(), True),\n",
    "    StructField(\"asin\", StringType(), True),\n",
    "    StructField(\"reviewerName\", StringType(), True),\n",
    "    StructField(\"reviewText\", StringType(), True),\n",
    "    StructField(\"overall\", DoubleType(), True),\n",
    "])\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Amazon Product Reviews Transformation\") \\\n",
    "    .config(\"spark.driver.memory\", \"8g\") \\\n",
    "    .config(\"spark.executor.memory\", \"8g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Read the file\n",
    "df = spark.read.schema(review_schema).parquet(BASE_FILE)\n",
    "\n",
    "# Drop the columns that are not needed (keep reviewerName for now)\n",
    "df = df.drop(\"reviewText\", \"overall\", \"asin\", \"reviewerName\")\n",
    "\n",
    "# Unique users and create new df with unique reviewerID and reviewerName\n",
    "df = df.select(\"reviewerID\").distinct()\n",
    "\n",
    "# Create UDF for gender detection\n",
    "\n",
    "# Infer gender from name\n",
    "df = df.withColumn(\"gender\", when(rand() < 0.5, \"male\").otherwise(\"female\"))\n",
    "\n",
    "print(f\"Total unique users: {df.count()}\")\n",
    "\n",
    "# Count null values\n",
    "reviewer_id_values_null = df.filter(col(\"reviewerID\").isNull()).count()\n",
    "gender_values_null = df.filter(col(\"gender\").isNull()).count()\n",
    "\n",
    "print(f\"Null reviewer ID values: {reviewer_id_values_null}\")\n",
    "print(f\"Null gender values: {gender_values_null}\")\n",
    "\n",
    "# Write to parquet\n",
    "df.write.mode(\"overwrite\").parquet(DEST_FILE)\n",
    "print(f\"User table written to: {DEST_FILE}\")\n",
    "\n",
    "# Clear everything before stopping\n",
    "spark.catalog.clearCache()\n",
    "\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b64bbf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Wrote all records to data/gold/user_table.parquet\n"
     ]
    }
   ],
   "source": [
    "from duckdb import connect\n",
    "\n",
    "con = connect()\n",
    "\n",
    "# File 1: 70% of the data\n",
    "file = \"data/gold/user_table.parquet\"\n",
    "\n",
    "con.execute(f\"\"\"\n",
    "    COPY (\n",
    "        SELECT *\n",
    "        FROM read_parquet('data/gold/user_table/*.parquet')\n",
    "    )\n",
    "    TO '{file}'\n",
    "    (FORMAT PARQUET, COMPRESSION SNAPPY);\n",
    "\"\"\")\n",
    "print(f\"✅ Wrote all records to {file}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b713e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6205624\n",
      "[Row(reviewerID='A2YO4SCWAWNYBI', gender='male'), Row(reviewerID='A3QJUWWAZ8LA52', gender='male'), Row(reviewerID='A3L7ZCFUJMWFV7', gender='female'), Row(reviewerID='A2EPFZAWK6UDJB', gender='female'), Row(reviewerID='A128NU439QI7UF', gender='female')]\n"
     ]
    }
   ],
   "source": [
    "# Initialize Schema for the data\n",
    "file = \"data/gold/user_table.parquet\"\n",
    "\n",
    "review_schema = StructType([\n",
    "    StructField(\"reviewerID\", StringType(), True),\n",
    "    StructField(\"gender\", StringType(), True),\n",
    "])\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Amazon Product Reviews Transformation\") \\\n",
    "    .config(\"spark.driver.memory\", \"8g\") \\\n",
    "    .config(\"spark.executor.memory\", \"8g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "df = spark.read.schema(review_schema).parquet(file)\n",
    "\n",
    "print(df.count())\n",
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0e7293",
   "metadata": {},
   "source": [
    "# Create user comments table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb8afcb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3015910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User comments table written to: data/gold/user_comments\n"
     ]
    }
   ],
   "source": [
    "BASE_FILE = \"data/silver/reviews_Cell_Phones_and_Accessories_30.parquet\"\n",
    "DEST_FILE = \"data/gold/user_comments\"\n",
    "\n",
    "# Initialize Schema for the data\n",
    "review_schema = StructType([\n",
    "    StructField(\"reviewerID\", StringType(), True),\n",
    "    StructField(\"asin\", StringType(), True),\n",
    "    StructField(\"reviewerName\", StringType(), True),\n",
    "    StructField(\"reviewText\", StringType(), True),\n",
    "    StructField(\"overall\", DoubleType(), True),\n",
    "])\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Amazon Product Reviews Transformation\") \\\n",
    "    .config(\"spark.driver.memory\", \"8g\") \\\n",
    "    .config(\"spark.executor.memory\", \"8g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "df = spark.read.schema(review_schema).parquet(BASE_FILE)\n",
    "\n",
    "# Drop the columns that are not needed (keep reviewerName for now)\n",
    "df = df.drop(\"overall\", \"reviewerName\")\n",
    "\n",
    "print(df.count())\n",
    "\n",
    "# Overwrite the user table with the new user comments table\n",
    "df.write.mode(\"overwrite\").parquet(DEST_FILE)\n",
    "print(f\"User comments table written to: {DEST_FILE}\")\n",
    "\n",
    "# Clear everything before stopping\n",
    "spark.catalog.clearCache()\n",
    "\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "edee4055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Wrote all records to data/gold/user_comments.parquet\n"
     ]
    }
   ],
   "source": [
    "con = connect()\n",
    "\n",
    "# File 1: 70% of the data\n",
    "file = \"data/gold/user_comments.parquet\"\n",
    "\n",
    "con.execute(f\"\"\"\n",
    "    COPY (\n",
    "        SELECT *\n",
    "        FROM read_parquet('data/gold/user_comments/*.parquet')\n",
    "    )\n",
    "    TO '{file}'\n",
    "    (FORMAT PARQUET, COMPRESSION SNAPPY);\n",
    "\"\"\")\n",
    "print(f\"✅ Wrote all records to {file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3a16dc3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3015910\n",
      "[Row(reviewerID='AKHCHD39R5KKD', asin='B01BLI4FWI', reviewText=\"It's a really good case.  If it had the built in screen protector it would be a great case,  and would've received the other two stars.\"), Row(reviewerID='A299CPUUY3E1QF', asin='B00U2STI12', reviewText='When using the metal ring on the edge of the case it is almost impossible to charge the phone unless the ring is removed.'), Row(reviewerID='AY3G1U2SGFINR', asin='B004WKH46W', reviewText='it is correctly fit for HTC inspire .I got it for very less price and i am very happy with this'), Row(reviewerID='A1S7PR7750I9T6', asin='B00LP0KTEG', reviewText='Perfect fit. Installed myself . made my phone look like new. No move of those plastic proctors for me.'), Row(reviewerID='A6MTZJ8TS84S5', asin='B00QZRYLBQ', reviewText='Don\\'t fall for \"edge-to-edge coverage for maximum protection\" description. It DOESN\\'T cover whole iPhone 6s plus screen! Also, it is a flat cover. It didn\\'t curve to fit the curved screen on iPhone 6s plus. A lot of dust already get into the edge in less than a day. Huge<a data-hook=\"product-link-linked\" class=\"a-link-normal\" href=\"/iPhone-6s-Plus-Screen-Protector-iPhone-6-Plus-Screen-Protector-Daswise-2015-Full-Screen-Anti-scratch-Tempered-Glass-Protectors-with-Curved-Edge-Cover-Edge-to-Edge-Protect-Your-5-5-Inches-Space-Gray-iPhone-6-6S-Plus-Screens-from-Drops-Impacts-HD-Clear-Bubble-free-Shockproof-3D-Touch-Compatible-5-5-Black/dp/B00QZRYLBQ/ref=cm_cr_arp_d_rvw_txt?ie=UTF8\">iPhone 6s Plus Screen Protector, iPhone 6 Plus Screen Protector, Daswise 2015 Full Screen Anti-scratch Tempered Glass Protectors with Curved Edge, Cover Edge-to-Edge, Protect Your 5.5 Inches Space Gray iPhone 6/6S Plus Screens from Drops & Impacts, HD Clear, Bubble-free Shockproof [3D Touch Compatible] (5.5 Black)</a>&nbsp;regret!!!!')]\n"
     ]
    }
   ],
   "source": [
    "# Initialize Schema for the data\n",
    "file = \"data/gold/user_comments.parquet\"\n",
    "\n",
    "review_schema = StructType([\n",
    "    StructField(\"reviewerID\", StringType(), True),\n",
    "    StructField(\"asin\", StringType(), True),\n",
    "    StructField(\"reviewText\", StringType(), True),\n",
    "])\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Amazon Product Reviews Transformation\") \\\n",
    "    .config(\"spark.driver.memory\", \"8g\") \\\n",
    "    .config(\"spark.executor.memory\", \"8g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "df = spark.read.schema(review_schema).parquet(file)\n",
    "\n",
    "print(df.count())\n",
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5e4b46",
   "metadata": {},
   "source": [
    "# Create data training table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "67184703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7037123\n",
      "+--------------------+--------------+\n",
      "|          reviewText|semanticDetect|\n",
      "+--------------------+--------------+\n",
      "|great quality and...|      positive|\n",
      "|The case is nice ...|      positive|\n",
      "|Doesn't fit my ph...|      negative|\n",
      "|Haven't used it a...|      positive|\n",
      "|I love these cove...|      positive|\n",
      "+--------------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data table written to: data/gold/training_data\n"
     ]
    }
   ],
   "source": [
    "BASE_FILE = \"data/silver/reviews_Cell_Phones_and_Accessories_70.parquet\"\n",
    "DEST_FILE = \"data/gold/training_data\"\n",
    "\n",
    "# Initialize Schema for the data\n",
    "review_schema = StructType([\n",
    "    StructField(\"reviewerID\", StringType(), True),\n",
    "    StructField(\"asin\", StringType(), True),\n",
    "    StructField(\"reviewerName\", StringType(), True),\n",
    "    StructField(\"reviewText\", StringType(), True),\n",
    "    StructField(\"overall\", DoubleType(), True),\n",
    "])\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Amazon Product Reviews Transformation\") \\\n",
    "    .config(\"spark.driver.memory\", \"8g\") \\\n",
    "    .config(\"spark.executor.memory\", \"8g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "df = spark.read.schema(review_schema).parquet(BASE_FILE)\n",
    "\n",
    "# Drop the columns that are not needed (keep reviewerName for now)\n",
    "df = df.drop(\"reviewerName\", \"reviewerID\", \"asin\")\n",
    "\n",
    "print(df.count())\n",
    "\n",
    "# Create a new column for semantic detection\n",
    "df = df.withColumn(\n",
    "    \"semanticDetect\", \n",
    "    when(col(\"overall\") > 3, \"positive\")\n",
    "    .when(col(\"overall\") < 3, \"negative\")\n",
    "    .otherwise(\"neutral\"))\n",
    "\n",
    "# Drop the overall column\n",
    "df = df.drop(\"overall\")\n",
    "\n",
    "print(df.show(5))\n",
    "\n",
    "# Overwrite the training data table\n",
    "df.write.mode(\"overwrite\").parquet(DEST_FILE)\n",
    "print(f\"Training data table written to: {DEST_FILE}\")\n",
    "\n",
    "# Clear everything before stopping\n",
    "spark.catalog.clearCache()\n",
    "\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e0a6de37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Wrote all records to data/gold/training_data.parquet\n"
     ]
    }
   ],
   "source": [
    "con = connect()\n",
    "\n",
    "# File 1: 70% of the data\n",
    "file = \"data/gold/training_data.parquet\"\n",
    "\n",
    "con.execute(f\"\"\"\n",
    "    COPY (\n",
    "        SELECT *\n",
    "        FROM read_parquet('data/gold/training_data/*.parquet')\n",
    "    )\n",
    "    TO '{file}'\n",
    "    (FORMAT PARQUET, COMPRESSION SNAPPY);\n",
    "\"\"\")\n",
    "print(f\"✅ Wrote all records to {file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "be6a01e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7037123\n",
      "[Row(reviewText='great quality and nicely finished', semanticDetect='positive'), Row(reviewText='The case is nice really skinny fix good, but the screen protector does not stick in the phone, in the corners there are bubbles, so my recommendation is to purchase other good screen protector and place it as IQ shield, I did it and now it is good.', semanticDetect='positive'), Row(reviewText=\"Doesn't fit my phone. Auxiliary does not lign up. Cannot use this case\", semanticDetect='negative'), Row(reviewText=\"Haven't used it a ton yet, but so far I am very happy. Not the highest quality, but definitely what I expected and its great for the price! I want more of these things because it really is very versatile and has many uses!\", semanticDetect='positive'), Row(reviewText='I love these covers easy to put on the phone', semanticDetect='positive')]\n",
      "+--------------+-------+\n",
      "|semanticDetect|  count|\n",
      "+--------------+-------+\n",
      "|      positive|5010181|\n",
      "|       neutral| 602391|\n",
      "|      negative|1424551|\n",
      "+--------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize Schema for the data\n",
    "file = \"data/gold/training_data.parquet\"\n",
    "\n",
    "review_schema = StructType([\n",
    "    StructField(\"reviewText\", StringType(), True),\n",
    "    StructField(\"semanticDetect\", StringType(), True),\n",
    "    \n",
    "])\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Amazon Product Reviews Transformation\") \\\n",
    "    .config(\"spark.driver.memory\", \"8g\") \\\n",
    "    .config(\"spark.executor.memory\", \"8g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "df = spark.read.schema(review_schema).parquet(file)\n",
    "\n",
    "print(df.count())\n",
    "print(df.head(5))\n",
    "\n",
    "# Count sentiment distribution\n",
    "df.groupBy(\"semanticDetect\").count().show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
