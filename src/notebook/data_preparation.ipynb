{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4534773",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "\n",
    "This notebook loads Amazon product reviews data (2014 dataset) from [Google Drive](\"https://drive.google.com/file/d/11fsXDGy_NpQMIHLowKNcTQoXUkX43x2f/view\") and uses PySpark to transform it into 3 parquet tables:\n",
    "\n",
    "- **User Table**: Contains `userID`, `userName`, and `gender` (gender is inferred from the `userName` field using the gender_guesser library)\n",
    "- **Training Data Table** (70% of reviews): Contains `reviewText` and `semanticDetect` (derived from the `overall` rating field)\n",
    "- **User Comments Table** (30% of reviews): Contains `reviewerID`, `reviewText`, and `overall` rating\n",
    "\n",
    "## Data Transformation Rules\n",
    "\n",
    "### Sentiment Classification (semanticDetect)\n",
    "The `semanticDetect` field is generated from the `overall` rating using the following rules:\n",
    "- If `overall` > 3 → `\"positive\"`\n",
    "- If `overall` < 3 → `\"negative\"`\n",
    "- If `overall` = 3 → `\"neutral\"`\n",
    "\n",
    "## Sample Review Structure\n",
    "```\n",
    "{\n",
    "  \"reviewerID\": \"A2SUAM1J3GNN3B\",\n",
    "  \"asin\": \"0000013714\",\n",
    "  \"reviewerName\": \"J. McDonald\",\n",
    "  \"helpful\": [2, 3],\n",
    "  \"reviewText\": \"I bought this for my husband who plays the piano. He is having a wonderful time playing these old hymns. The music is at times hard to read because we think the book was published for singing from more than playing from. Great purchase though!\",\n",
    "  \"overall\": 5.0,\n",
    "  \"summary\": \"Heavenly Highway Hymns\",\n",
    "  \"unixReviewTime\": 1252800000,\n",
    "  \"reviewTime\": \"09 13, 2009\"\n",
    "}\n",
    "```\n",
    "\n",
    "**Field Descriptions:**\n",
    "- `reviewerID`: Unique identifier for the reviewer (e.g., A2SUAM1J3GNN3B)\n",
    "- `asin`: Amazon Standard Identification Number for the product (e.g., 0000013714)\n",
    "- `reviewerName`: Name of the reviewer\n",
    "- `helpful`: Helpfulness rating as [helpful_votes, total_votes] (e.g., [2, 3] means 2 out of 3 people found it helpful)\n",
    "- `reviewText`: Full text content of the review\n",
    "- `overall`: Product rating on a 1-5 scale\n",
    "- `summary`: Brief summary/title of the review\n",
    "- `unixReviewTime`: Review timestamp in Unix format\n",
    "- `reviewTime`: Human-readable review date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81999c7",
   "metadata": {},
   "source": [
    "# Load data from Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936cd845",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdown\n",
    "import os\n",
    "\n",
    "os.makedirs(\"data/bronze\", exist_ok=True)\n",
    "\n",
    "# Load data from Google Drive\n",
    "file_url = \"https://drive.google.com/file/d/11fsXDGy_NpQMIHLowKNcTQoXUkX43x2f/view\"\n",
    "output_path = \"data/bronze/reviews_Cell_Phones_and_Accessories.jsonl\"\n",
    "gdown.download(file_url, output_path, fuzzy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ec8eeeb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"data/bronze/reviews_Cell_Phones_and_Accessories.jsonl\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00813f3f",
   "metadata": {},
   "source": [
    "# Remove rows with null values in reviewText and convert to parquet format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fc250111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(reviewerID='A1GG51FWU0XQYH', asin='098949232X', reviewerName='Paul Williams', helpful=None, reviewText='If your into space this is the Calendar for you.', overall=5.0, summary='Five Stars', unixReviewTime=1416355200, reviewTime='11 19, 2014'), Row(reviewerID='AVFIDS9RK38E0', asin='098949232X', reviewerName='Sean Powell', helpful=None, reviewText='Awesome pictures!', overall=5.0, summary='Five Stars', unixReviewTime=1416355200, reviewTime='11 19, 2014'), Row(reviewerID='A2S4AVR5SJ7KMI', asin='098949232X', reviewerName='Tom Davis', helpful=None, reviewText='Great wall art and information for space exploration minded people.', overall=5.0, summary='Five Stars', unixReviewTime=1416355200, reviewTime='11 19, 2014'), Row(reviewerID='AEMMMVOR9BFLI', asin='098949232X', reviewerName='Kwajmeck', helpful=None, reviewText='As always, it is a quality calendar full of very interesting space-related photos and information.  I love it.  I buy a new one every year.', overall=5.0, summary='I love it. I buy a new one every year', unixReviewTime=1416355200, reviewTime='11 19, 2014'), Row(reviewerID='A2DZXMBTY7KLYP', asin='098949232X', reviewerName='ScottG43', helpful=None, reviewText='This is a fantastic calendar. This is my third year purchasing it. It is sturdy and well put together and has a bunch of awesome information in it.', overall=5.0, summary='Great Calendar.', unixReviewTime=1416355200, reviewTime='11 19, 2014')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records: 10063255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records after dropping columns: 10047785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 10047785 records to data/bronze/reviews_Cell_Phones_and_Accessories\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, when, udf\n",
    "from pyspark.sql.types import (\n",
    "    StructType,\n",
    "    StructField,\n",
    "    StringType,\n",
    "    IntegerType,\n",
    "    DoubleType,\n",
    "    ArrayType,\n",
    "    LongType,\n",
    "    BooleanType\n",
    ")\n",
    "import re\n",
    "\n",
    "# Count null values\n",
    "def is_effectively_empty(text: str) -> bool:\n",
    "    if text is None:\n",
    "        return True\n",
    "    return re.sub(r\"[^A-Za-z0-9]+\", \"\", text) == \"\"\n",
    "\n",
    "# Initialize Schema for the data\n",
    "review_schema = StructType([\n",
    "    StructField(\"reviewerID\", StringType(), True),\n",
    "    StructField(\"asin\", StringType(), True),\n",
    "    StructField(\"reviewerName\", StringType(), True),\n",
    "    StructField(\"helpful\", ArrayType(IntegerType()), True),\n",
    "    StructField(\"reviewText\", StringType(), True),\n",
    "    StructField(\"overall\", DoubleType(), True),\n",
    "    StructField(\"summary\", StringType(), True),\n",
    "    StructField(\"unixReviewTime\", LongType(), True),\n",
    "    StructField(\"reviewTime\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Amazon Product Reviews Transformation\") \\\n",
    "    .config(\"spark.driver.memory\", \"8g\") \\\n",
    "    .config(\"spark.executor.memory\", \"8g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "df = spark.read.schema(review_schema).json(output_path, multiLine=False)\n",
    "\n",
    "# Cache the dataframe\n",
    "print(df.head(5))\n",
    "\n",
    "# Count the number of records\n",
    "records = df.count()\n",
    "print(f\"Total records: {records}\")\n",
    "\n",
    "# Drop unused columns\n",
    "df = df.drop(\"helpful\", \"summary\", \"reviewTime\", \"unixReviewTime\")\n",
    "\n",
    "# Remove rows with null values in reviewText\n",
    "is_empty_udf = udf(is_effectively_empty, BooleanType())\n",
    "\n",
    "# df = df.filter(col(\"reviewText\").isNotNull())\n",
    "# df = df.filter(col(\"reviewerName\").isNotNull())\n",
    "df = df.filter(~is_empty_udf(col(\"reviewText\")))\n",
    "df = df.filter(~is_empty_udf(col(\"reviewerName\")))\n",
    "\n",
    "records2 = df.count()\n",
    "print(f\"Total records after dropping columns: {records2}\")\n",
    "\n",
    "# Write Parquet\n",
    "parquet_path = \"data/bronze/reviews_Cell_Phones_and_Accessories\"\n",
    "df.write.mode(\"overwrite\").parquet(parquet_path)\n",
    "print(f\"Wrote {records2} records to {parquet_path}\")\n",
    "\n",
    "# Clear everything before stopping\n",
    "spark.catalog.clearCache()\n",
    "\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76068a0",
   "metadata": {},
   "source": [
    "## Merge parquet files into 1 file using duckdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f193a07b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Wrote all records to data/silver/reviews_Cell_Phones_and_Accessories.parquet\n"
     ]
    }
   ],
   "source": [
    "from duckdb import connect\n",
    "\n",
    "con = connect()\n",
    "\n",
    "file = \"data/silver/reviews_Cell_Phones_and_Accessories.parquet\"\n",
    "con.execute(f\"\"\"\n",
    "    COPY (\n",
    "        SELECT *\n",
    "        FROM read_parquet('data/bronze/reviews_Cell_Phones_and_Accessories/*.parquet')\n",
    "    )\n",
    "    TO '{file}'\n",
    "    (FORMAT PARQUET, COMPRESSION SNAPPY);\n",
    "\"\"\")\n",
    "print(f\"✅ Wrote all records to {file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7dd6a71",
   "metadata": {},
   "source": [
    "# Check null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6f4b58bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records: 10047785\n",
      "[Row(reviewerID='A1GG51FWU0XQYH', asin='098949232X', reviewerName='Paul Williams', reviewText='If your into space this is the Calendar for you.', overall=5.0), Row(reviewerID='AVFIDS9RK38E0', asin='098949232X', reviewerName='Sean Powell', reviewText='Awesome pictures!', overall=5.0), Row(reviewerID='A2S4AVR5SJ7KMI', asin='098949232X', reviewerName='Tom Davis', reviewText='Great wall art and information for space exploration minded people.', overall=5.0), Row(reviewerID='AEMMMVOR9BFLI', asin='098949232X', reviewerName='Kwajmeck', reviewText='As always, it is a quality calendar full of very interesting space-related photos and information.  I love it.  I buy a new one every year.', overall=5.0), Row(reviewerID='A2DZXMBTY7KLYP', asin='098949232X', reviewerName='ScottG43', reviewText='This is a fantastic calendar. This is my third year purchasing it. It is sturdy and well put together and has a bunch of awesome information in it.', overall=5.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null review Text values: 0\n",
      "Null review Overall values: 0\n",
      "Null asin values: 0\n",
      "Null reviewer ID values: 0\n",
      "Null reviewer Name values: 0\n",
      "Empty review Text values: 0\n",
      "Empty reviewer Name values: 0\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import BooleanType\n",
    "\n",
    "FILE = \"data/silver/reviews_Cell_Phones_and_Accessories.parquet\"\n",
    "\n",
    "# Initialize Schema for the data\n",
    "review_schema = StructType([\n",
    "    StructField(\"reviewerID\", StringType(), True),\n",
    "    StructField(\"asin\", StringType(), True),\n",
    "    StructField(\"reviewerName\", StringType(), True),\n",
    "    StructField(\"reviewText\", StringType(), True),\n",
    "    StructField(\"overall\", DoubleType(), True),\n",
    "])\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Amazon Product Reviews Transformation\") \\\n",
    "    .config(\"spark.driver.memory\", \"8g\") \\\n",
    "    .config(\"spark.executor.memory\", \"8g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "df = spark.read.schema(review_schema).parquet(FILE)\n",
    "\n",
    "# Cache the dataframe\n",
    "df.cache()\n",
    "\n",
    "# Count the number of records\n",
    "records = df.count()\n",
    "print(f\"Total records: {records}\")\n",
    "\n",
    "print(df.head(5))\n",
    "\n",
    "# Count null values\n",
    "def is_effectively_empty(text: str) -> bool:\n",
    "    if text is None:\n",
    "        return True\n",
    "    return re.sub(r\"[^A-Za-z0-9]+\", \"\", text) == \"\"\n",
    "\n",
    "# Create UDF\n",
    "is_empty_udf = udf(is_effectively_empty, BooleanType())\n",
    "\n",
    "review_text_values_null = df.filter(col(\"reviewText\").isNull()).count()\n",
    "review_overall_values_null = df.filter(col(\"overall\").isNull()).count()\n",
    "asin_values_null = df.filter(col(\"asin\").isNull()).count()\n",
    "reviewer_id_values_null = df.filter(col(\"reviewerID\").isNull()).count()\n",
    "reviewer_name_values_null = df.filter(col(\"reviewerName\").isNull()).count()\n",
    "empty_text_count = df.filter(is_empty_udf(col(\"reviewText\"))).count()\n",
    "empty_name_count = df.filter(is_empty_udf(col(\"reviewerName\"))).count()\n",
    "\n",
    "print(f\"Null review Text values: {review_text_values_null}\")\n",
    "print(f\"Null review Overall values: {review_overall_values_null}\")\n",
    "print(f\"Null asin values: {asin_values_null}\")\n",
    "print(f\"Null reviewer ID values: {reviewer_id_values_null}\")\n",
    "print(f\"Null reviewer Name values: {reviewer_name_values_null}\")\n",
    "print(f\"Empty review Text values: {empty_text_count}\")\n",
    "print(f\"Empty reviewer Name values: {empty_name_count}\")\n",
    "# Clear everything before stopping\n",
    "spark.catalog.clearCache()\n",
    "\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294d62fe",
   "metadata": {},
   "source": [
    "# Create User Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ad6174f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique users: 6202980\n",
      "Null reviewer ID values: 0\n",
      "Null gender values: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User table written to: data/gold/user_table\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, rand\n",
    "from pyspark.sql.types import (\n",
    "    StructType,\n",
    "    StructField,\n",
    "    StringType,\n",
    "    DoubleType\n",
    ")\n",
    "\n",
    "BASE_FILE = \"data/silver/reviews_Cell_Phones_and_Accessories.parquet\"\n",
    "DEST_FILE = \"data/gold/user_table\"\n",
    "\n",
    "# Initialize Schema for the data\n",
    "review_schema = StructType([\n",
    "    StructField(\"reviewerID\", StringType(), True),\n",
    "    StructField(\"asin\", StringType(), True),\n",
    "    StructField(\"reviewerName\", StringType(), True),\n",
    "    StructField(\"reviewText\", StringType(), True),\n",
    "    StructField(\"overall\", DoubleType(), True),\n",
    "])\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Amazon Product Reviews Transformation\") \\\n",
    "    .config(\"spark.driver.memory\", \"8g\") \\\n",
    "    .config(\"spark.executor.memory\", \"8g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Read the file\n",
    "df = spark.read.schema(review_schema).parquet(BASE_FILE)\n",
    "\n",
    "# Drop the columns that are not needed (keep reviewerName for now)\n",
    "df = df.drop(\"reviewText\", \"overall\", \"asin\", \"reviewerName\")\n",
    "\n",
    "# Unique users and create new df with unique reviewerID and reviewerName\n",
    "df = df.select(\"reviewerID\").distinct()\n",
    "\n",
    "# Create UDF for gender detection\n",
    "\n",
    "# Infer gender from name\n",
    "df = df.withColumn(\"gender\", when(rand() < 0.5, \"male\").otherwise(\"female\"))\n",
    "\n",
    "print(f\"Total unique users: {df.count()}\")\n",
    "\n",
    "# Count null values\n",
    "reviewer_id_values_null = df.filter(col(\"reviewerID\").isNull()).count()\n",
    "gender_values_null = df.filter(col(\"gender\").isNull()).count()\n",
    "\n",
    "print(f\"Null reviewer ID values: {reviewer_id_values_null}\")\n",
    "print(f\"Null gender values: {gender_values_null}\")\n",
    "\n",
    "# Write to parquet\n",
    "df.write.mode(\"overwrite\").parquet(DEST_FILE)\n",
    "print(f\"User table written to: {DEST_FILE}\")\n",
    "\n",
    "# Clear everything before stopping\n",
    "spark.catalog.clearCache()\n",
    "\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5b64bbf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Wrote all records to data/gold/user_table.parquet\n"
     ]
    }
   ],
   "source": [
    "from duckdb import connect\n",
    "\n",
    "con = connect()\n",
    "\n",
    "# File 1: 70% of the data\n",
    "file = \"data/gold/user_table.parquet\"\n",
    "\n",
    "con.execute(f\"\"\"\n",
    "    COPY (\n",
    "        SELECT *\n",
    "        FROM read_parquet('data/gold/user_table/*.parquet')\n",
    "    )\n",
    "    TO '{file}'\n",
    "    (FORMAT PARQUET, COMPRESSION SNAPPY);\n",
    "\"\"\")\n",
    "print(f\"✅ Wrote all records to {file}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1b713e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6202980\n",
      "[Row(reviewerID='A2YO4SCWAWNYBI', gender='female'), Row(reviewerID='A3QJUWWAZ8LA52', gender='female'), Row(reviewerID='A3L7ZCFUJMWFV7', gender='male'), Row(reviewerID='A2EPFZAWK6UDJB', gender='male'), Row(reviewerID='A128NU439QI7UF', gender='female')]\n"
     ]
    }
   ],
   "source": [
    "# Initialize Schema for the data\n",
    "file = \"data/gold/user_table.parquet\"\n",
    "\n",
    "review_schema = StructType([\n",
    "    StructField(\"reviewerID\", StringType(), True),\n",
    "    StructField(\"gender\", StringType(), True),\n",
    "])\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Amazon Product Reviews Transformation\") \\\n",
    "    .config(\"spark.driver.memory\", \"8g\") \\\n",
    "    .config(\"spark.executor.memory\", \"8g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "df = spark.read.schema(review_schema).parquet(file)\n",
    "\n",
    "print(df.count())\n",
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0e7293",
   "metadata": {},
   "source": [
    "# Create user comments table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fb8afcb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10047785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 7:===================================================>     (10 + 1) / 11]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User comments table written to: data/gold/user_comments\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "BASE_FILE = \"data/silver/reviews_Cell_Phones_and_Accessories.parquet\"\n",
    "DEST_FILE = \"data/gold/user_comments\"\n",
    "\n",
    "# Initialize Schema for the data\n",
    "review_schema = StructType([\n",
    "    StructField(\"reviewerID\", StringType(), True),\n",
    "    StructField(\"asin\", StringType(), True),\n",
    "    StructField(\"reviewerName\", StringType(), True),\n",
    "    StructField(\"reviewText\", StringType(), True),\n",
    "    StructField(\"overall\", DoubleType(), True),\n",
    "])\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Amazon Product Reviews Transformation\") \\\n",
    "    .config(\"spark.driver.memory\", \"8g\") \\\n",
    "    .config(\"spark.executor.memory\", \"8g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "df = spark.read.schema(review_schema).parquet(BASE_FILE)\n",
    "\n",
    "# Drop the columns that are not needed (keep reviewerName for now)\n",
    "df = df.drop(\"overall\", \"reviewerName\")\n",
    "\n",
    "print(df.count())\n",
    "\n",
    "# Overwrite the user table with the new user comments table\n",
    "df.write.mode(\"overwrite\").parquet(DEST_FILE)\n",
    "print(f\"User comments table written to: {DEST_FILE}\")\n",
    "\n",
    "# Clear everything before stopping\n",
    "spark.catalog.clearCache()\n",
    "\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "edee4055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Wrote all records to data/gold/user_comments.parquet\n"
     ]
    }
   ],
   "source": [
    "con = connect()\n",
    "\n",
    "# File 1: 70% of the data\n",
    "file = \"data/gold/user_comments.parquet\"\n",
    "\n",
    "con.execute(f\"\"\"\n",
    "    COPY (\n",
    "        SELECT *\n",
    "        FROM read_parquet('data/gold/user_comments/*.parquet')\n",
    "    )\n",
    "    TO '{file}'\n",
    "    (FORMAT PARQUET, COMPRESSION SNAPPY);\n",
    "\"\"\")\n",
    "print(f\"✅ Wrote all records to {file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3a16dc3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10047785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(reviewerID='A1GG51FWU0XQYH', asin='098949232X', reviewText='If your into space this is the Calendar for you.'), Row(reviewerID='AVFIDS9RK38E0', asin='098949232X', reviewText='Awesome pictures!'), Row(reviewerID='A2S4AVR5SJ7KMI', asin='098949232X', reviewText='Great wall art and information for space exploration minded people.'), Row(reviewerID='AEMMMVOR9BFLI', asin='098949232X', reviewText='As always, it is a quality calendar full of very interesting space-related photos and information.  I love it.  I buy a new one every year.'), Row(reviewerID='A2DZXMBTY7KLYP', asin='098949232X', reviewText='This is a fantastic calendar. This is my third year purchasing it. It is sturdy and well put together and has a bunch of awesome information in it.')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Initialize Schema for the data\n",
    "file = \"data/gold/user_comments.parquet\"\n",
    "\n",
    "review_schema = StructType([\n",
    "    StructField(\"reviewerID\", StringType(), True),\n",
    "    StructField(\"asin\", StringType(), True),\n",
    "    StructField(\"reviewText\", StringType(), True),\n",
    "])\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Amazon Product Reviews Transformation\") \\\n",
    "    .config(\"spark.driver.memory\", \"8g\") \\\n",
    "    .config(\"spark.executor.memory\", \"8g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "df = spark.read.schema(review_schema).parquet(file)\n",
    "\n",
    "print(df.count())\n",
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf31150",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
