{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86143a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning::Spark Session already created, some configs may not take.\n",
      "Spark NLP version: 6.2.3\n",
      "Spark version: 3.3.1\n"
     ]
    }
   ],
   "source": [
    "import sparknlp\n",
    "# spark = sparknlp.start() \n",
    "spark = sparknlp.start(apple_silicon=True)\n",
    "\n",
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "from pyspark.ml import *\n",
    "import pyspark\n",
    "print(f\"Spark NLP version: {sparknlp.version()}\")\n",
    "print(f\"Spark version: {pyspark.__version__}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b37bd782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfhub_use download started this may take some time.\n",
      "25/12/24 16:12:28 WARN S3AbortableInputStream: Not all bytes were read from the S3ObjectInputStream, aborting HTTP connection. This is likely an error and may result in sub-optimal behavior. Request only the bytes you need via a ranged GET or drain the input stream after use.\n",
      "Approximate size to download 923.7 MB\n",
      "[OK!]\n",
      "sentimentdl_use_twitter download started this may take some time.\n",
      "25/12/24 16:12:32 WARN S3AbortableInputStream: Not all bytes were read from the S3ObjectInputStream, aborting HTTP connection. This is likely an error and may result in sub-optimal behavior. Request only the bytes you need via a ranged GET or drain the input stream after use.\n",
      "Approximate size to download 11.4 MB\n",
      "[OK!]\n",
      "Pipeline defined successfully!\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"sentimentdl_use_twitter\"\n",
    "\n",
    "documentAssembler = DocumentAssembler()\\\n",
    "    .setInputCol(\"reviewText\")\\\n",
    "    .setOutputCol(\"document\")\n",
    "    \n",
    "use = UniversalSentenceEncoder.pretrained(name=\"tfhub_use\", lang=\"en\")\\\n",
    ".setInputCols([\"document\"])\\\n",
    ".setOutputCol(\"sentence_embeddings\")\n",
    "\n",
    "\n",
    "sentimentdl = SentimentDLModel.pretrained(name=MODEL_NAME, lang=\"en\")\\\n",
    "    .setInputCols([\"sentence_embeddings\"])\\\n",
    "    .setOutputCol(\"sentiment\")\n",
    "\n",
    "nlpPipeline = Pipeline(\n",
    "    stages = [\n",
    "        documentAssembler,\n",
    "        use,\n",
    "        sentimentdl\n",
    "        ])\n",
    "\n",
    "print(\"Pipeline defined successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6813af20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fitting pipeline structure (no training involved)...\n",
      "Pipeline ready for inference!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nFitting pipeline structure (no training involved)...\")\n",
    "empty_df = spark.createDataFrame([[\"\"]], [\"reviewText\"])\n",
    "\n",
    "pipelineModel = nlpPipeline.fit(empty_df)\n",
    "print(\"Pipeline ready for inference!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "48df3036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap your trained model\n",
    "light_pipeline = LightPipeline(pipelineModel)\n",
    "\n",
    "# Instant inference on a simple string (no Spark overhead)\n",
    "result = light_pipeline.annotate(\"Instant inference on a simple string (no Spark overhead)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c4e8955d",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentiment\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m result:\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msentiment\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo sentiment found\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "if \"sentiment\" in result:\n",
    "    print(result[\"sentiment\"][1])\n",
    "else:\n",
    "    print(\"No sentiment found\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
